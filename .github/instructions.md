Aqui est√° a tradu√ß√£o t√©cnica e adaptada do guia, mantendo a precis√£o terminol√≥gica e a eleg√¢ncia que o projeto exige.

**Objetivo:** Orienta√ß√£o curta e pr√°tica para ajudar um agente de IA a ser produtivo rapidamente ao trabalhar neste reposit√≥rio (raspagem, normaliza√ß√£o e processamento de metadados do repositorio.unb.br).

---

## O panorama geral (o que roda e onde)

* **Coletores (Harvesters)** (`src/harvesters/riunb/`): Raspam (fazem *scrape*) as p√°ginas do reposit√≥rio da UnB e produzem arquivos CSV com carimbos de data/hora (timestamps). Arquivos principais: `riunb_author.py`, `riunb_subjects.py`, `rinb_advisor.py`.
* **Processadores (Processors)** (`src/processors/`): Transformam e higienizam metadados XML (dublin_core) usando CSVs de refer√™ncia. Arquivo principal: `organizador_metadados_unb.py`.
* **Detectores de duplicatas / auditores** (`src/duplicatas/`): Utilit√°rios para detectar termos e autores quase duplicados. Arquivos principais: `indexador_artesanal.py`, `verificador_autores.py`.

**Fluxo de Dados:** Coletores -> CSV (data/raw ou diret√≥rio de trabalho) -> ingest√£o manual ou via script -> `organizador_metadados_unb.py` processa pastas XML e grava/sobrescreve arquivos `dublin_core.xml`. Os detectores de duplicatas operam nos CSVs (ou listas de frequ√™ncia produzidas).

---

## Comandos de execu√ß√£o r√°pida / fluxos de trabalho do desenvolvedor ‚úÖ

* **Executar um coletor (cria CSV):**
* `python src/harvesters/riunb/riunb_author.py`
* `python src/harvesters/riunb/riunb_subjects.py`
* `python src/harvesters/riunb/rinb_advisor.py`


* **Executar o processador (interativo):**
* `python src/processors/organizador_metadados_unb.py` (ele solicita um caminho de pasta; armazena o √∫ltimo caminho utilizado em `.gid_last_path`)


* **Executar verifica√ß√£o de duplicatas / auditorias:**
* `python src/duplicatas/indexador_artesanal.py` (nome do arquivo configur√°vel e constante `SENSIBILIDADE`)
* `python src/duplicatas/verificador_autores.py`



**Notas:**

* Os coletores criam sa√≠das nomeadas como `riunb_<tipo>_scraping_YYYYMMDD_HHMM.csv` (timestamps ISO).
* Muitos scripts esperam codifica√ß√£o UTF-8 (use `utf-8-sig` ao ler CSVs exportados pelo Excel).

---

## Padr√µes importantes e conven√ß√µes do projeto üîß

* **Nomenclatura:** Os nomes dos arquivos incluem **timestamps ISO** para reprodutibilidade e para evitar colis√µes.
* **Sess√µes de Coleta:** Os coletores usam um padr√£o compartilhado `configurar_sessao()`: `requests.Session()` + `urllib3.Retry` + um `time.sleep(2.0)` polido entre as requisi√ß√µes. Respeite este padr√£o ao adicionar novos scrapers.
* **Formato CSV:** Geralmente `Termo,Frequ√™ncia,Offset,Timestamp_Coleta` ‚Äî os analisadores (parsers) esperam a frequ√™ncia como num√©rico; alguns leitores usam detec√ß√£o heur√≠stica de cabe√ßalho.
* **Limiares de Correspond√™ncia Difusa (Fuzzy Matching):** S√£o constantes expl√≠citas pr√≥ximas ao topo dos arquivos:
* Padr√£o do `IndexadorArtesanal`: `threshold=70`
* `verificador_autores.py`: `LIMITE_SIMILARIDADE = 0.88`
* `organizador_metadados_unb.py`: `THRESHOLD_ADVISOR = 90`, `THRESHOLD_KEYWORD = 90`
* *Ajuste com cuidado* ‚Äî estes valores codificam os compromissos do dom√≠nio entre abrang√™ncia (recall) e falsos positivos.


* **Normaliza√ß√£o de Caracteres:** Fun√ß√µes como `normalizar` / `aplicar_regra_caracteres` lidam com acentos, caixa (mai√∫scula/min√∫scula) e regras para palavras curtas (preservando acr√¥nimos como `UnB`, `DF`). Siga-as ao normalizar campos.
* **Efeitos Colaterais na Sa√≠da:** O `organizador_metadados_unb.py` sobrescreve/cria `dublin_core.xml` dentro de cada pasta de item; ele tamb√©m apaga o arquivo XML original se processou um arquivo que n√£o era `dublin_core`.

---

## Integra√ß√µes externas / depend√™ncias ‚öôÔ∏è

* **Web:** `https://repositorio.unb.br` (os scrapers assumem a estrutura HTML: elementos `li.list-group-item` com `a` e `span.badge`). Mudan√ßas no site podem quebrar os scrapers.
* **CSVs de Refer√™ncia:** Para orientadores/palavras-chave, s√£o referenciados com caminhos absolutos em `organizador_metadados_unb.py` (vari√°veis: `CAMINHO_CSV_ADVISORS`, `CAMINHO_CSV_KEYWORDS`). Certifique-se de que esses caminhos estejam dispon√≠veis ou atualize-os para caminhos locais do projeto.
* **Principais bibliotecas Python utilizadas:** `requests`, `beautifulsoup4`, `pandas`, `rapidfuzz`/`thefuzz`, `unidecode`, `xml.etree.ElementTree`.

**Configura√ß√£o sugerida do ambiente de desenvolvimento (descoberta a partir dos imports):**

```bash
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install pandas requests beautifulsoup4 rapidfuzz thefuzz unidecode

```

---

## Estilo de c√≥digo e dicas comportamentais para edi√ß√µes ‚úçÔ∏è

* **UX:** Preserve as mensagens em portugu√™s voltadas ao usu√°rio e os logs baseados em emojis (eles s√£o a UX do projeto).
* **Robustez:** Mantenha o padr√£o `requests.Session()` + `Retry` para scrapers robustos e mantenha pequenos atrasos (2s) por polidez/cortesia.
* **Algoritmos de Texto:** Prefira `token_set_ratio` (rapidfuzz) para compara√ß√µes termo-vs-termo (usado em `indexador_artesanal.py`) e `fuzz.token_sort_ratio` em `organizador_metadados_unb.py` para buscas difusas (fuzzy lookups) contra dicion√°rios CSV.
* **Execu√ß√£o:** Ao adicionar funcionalidades, adicione um exemplo curto inline no bloco `__main__` do mesmo arquivo para manter os scripts execut√°veis via CLI (linha de comando).

---

## Armadilhas conhecidas / Pontos de aten√ß√£o ‚ö†Ô∏è

* **Performance:** Entradas grandes (50k+ linhas) podem tornar as passagens difusas (fuzzy passes) lentas e pesadas na mem√≥ria. O `indexador_artesanal.py` avisa sobre minutos de processamento e marca termos agrupados agressivamente para reduzir relatos duplicados.
* **Caminhos Hardcoded:** V√°rios caminhos est√£o codificados de forma r√≠gida (caminhos absolutos em `organizador_metadados_unb.py`). Atualize-os antes de rodar em um ambiente diferente.
* **Testes:** N√£o h√° testes automatizados ou CI atualmente; execute scripts em pequenos conjuntos de amostra e inspecione manualmente as sa√≠das CSV/XML produzidas.

---

## Onde procurar exemplos r√°pidos no reposit√≥rio üîé

* **Padr√£o de Coleta (Harvester):** `src/harvesters/riunb/riunb_subjects.py` (configura√ß√£o de sess√£o, sa√≠da CSV, polidez e detec√ß√£o de repeti√ß√£o).
* **Transforma√ß√µes do Processador:** `src/processors/organizador_metadados_unb.py` (l√≥gica de correspond√™ncia de assunto/orientador, tags obrigat√≥rias, regras de higieniza√ß√£o).
* **Detec√ß√£o de Duplicatas:** `src/duplicatas/indexador_artesanal.py` e `src/duplicatas/verificador_autores.py` (normaliza√ß√£o e heur√≠sticas de pontua√ß√£o).
